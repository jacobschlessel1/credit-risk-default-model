---
title: "Expected Loss (EL) Modeling"
author: "Jacob Schlessel"
format: html
execute:
  echo: true
  warning: false
  message: false
---

## Purpose

This notebook will combine the PD and LGD models into a singular model 
that predicts the expected loss (EL) of a loan at the time of loan 
origination. 

## Setup

This model will only be trained on loans that originated after 2016, when 
credit utilization data for borrowers began to be collected. This will 
generate more accurate predictions for loss and gives the lender valuable 
information in granting loans going forward. 

Additionally, the combined model for predicting expected loss will only utilize 
the XGBoost models for both probability of default and loss given default, 
as these are the models that exhibited the best, most balanced performance 
in the context of lending.

```{python}
import pandas as pd
import warnings
warnings.filterwarnings("ignore")


df_full = pd.read_parquet(
    "../data/processed/accepted_clean.parquet",
    engine="pyarrow"
)

pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", None)

# Non-current, defaulted loans for LGD
df_lgd = df_full[
    (df_full["default"] == 1) &
    (df_full["current_flag"] == 0)
].copy()
```

```{python}
# Create lgd variable
df_lgd["total_recovered"] = (
    df_lgd["total_rec_prncp"].fillna(0)
    + df_lgd["total_rec_int"].fillna(0)
    + df_lgd["total_rec_late_fee"].fillna(0)
    + df_lgd["recoveries"].fillna(0)
    - df_lgd["collection_recovery_fee"].fillna(0)
)

df_lgd["lgd"] = 1 - (df_lgd["total_recovered"] / df_lgd["loan_amnt"])
df_lgd["lgd"] = df_lgd["lgd"].clip(lower=0, upper=1)
```

### PD Model (same as before)

```{python}
# Non-current loans for PD
df = df_full.loc[df_full["current_flag"] == 0].copy()

y = df["default"]

pred_cat_pd = [
    "term", "region", "home_ownership"]

# Numeric predictor variables
pred_num_pd = [

    # loan structure
    "loan_amnt",

    # borrower capacity
    "annual_inc",
    "emp_length",
    "dti",

    # credit quality
    "fico_range_low",
    "fico_range_high",
    "delinq_2yrs",
    "pub_rec",
    "pub_rec_bankruptcies",
    "collections_12_mths_ex_med",
    "chargeoff_within_12_mths",
    "tax_liens",

    # credit account info
    "revol_bal",
    "revol_util",
    "total_bal_ex_mort",
    "avg_cur_bal",
    "bc_util",
    "percent_bc_gt_75",
    "bc_open_to_buy",
    "total_rev_hi_lim",
    "total_bc_limit",
    "total_il_high_credit_limit",

    # credit depth & activity
    "open_acc",
    "total_acc",
    "mort_acc",
    "inq_last_6mths",
    "acc_open_past_24mths",
    "num_rev_accts",
    "num_il_tl",
    "num_op_rev_tl",
    "num_sats",


    # flag variables
    "joint_flag",
    "verified_flag",
    "verified_flag_joint",
    "whole_loan_flag",

    # structural missingness flags
    "mths_since_last_record_flag",
    "mths_since_recent_bc_dlq_flag",
    "mths_since_last_major_derog_flag",
    "mths_since_recent_revol_delinq_flag",
    "mths_since_last_delinq_flag",
]


# Conditional joint variables
joint_numeric_pred_pd = [
    "sec_app_mths_since_last_major_derog",
    "sec_app_revol_util",
    "revol_bal_joint",
    "sec_app_open_acc",
    "sec_app_num_rev_accts",
    "sec_app_inq_last_6mths",
    "sec_app_mort_acc",
    "sec_app_open_act_il",
    "sec_app_fico_range_low",
    "sec_app_fico_range_high",
    "sec_app_chargeoff_within_12_mths",
    "sec_app_collections_12_mths_ex_med",
    "dti_joint",
    "annual_inc_joint"
]

joint_conditionals_pd = []

for var in joint_numeric_pred_pd:
    df[var] = df[var].fillna(0)
    df[f"{var}_active"] = df["joint_flag"] * df[var]
    joint_conditionals_pd.append(f"{var}_active")

flag_to_var = {
    "mths_since_last_record_flag": "mths_since_last_record",
    "mths_since_recent_bc_dlq_flag": "mths_since_recent_bc_dlq",
    "mths_since_last_major_derog_flag": "mths_since_last_major_derog",
    "mths_since_recent_revol_delinq_flag": "mths_since_recent_revol_delinq",
    "mths_since_last_delinq_flag": "mths_since_last_delinq",
}

interaction_delinq_pd = []

for flag, var in flag_to_var.items():
    df[var] = df[var].replace(999, 0).fillna(0)
    df[f"{var}_active"] = df[flag] * df[var]
    interaction_delinq_pd.append(f"{var}_active")

# Only use post-2016 data
df["post_2016"] = df["issue_d"].dt.year >= 2016

df["post_2016"].value_counts().rename({
    False: "pre_2016",
    True: "post_2016"
})

df_post2016 = df[df["issue_d"].dt.year >= 2016].copy()

# list of 2016 onwards credit utilization variables
recent_credit_vars_2016_pd = [
    "il_util",
    "mths_since_rcnt_il",
    "all_util",
    "open_acc_6m",
    "inq_last_12m",
    "total_cu_tl",
    "open_il_24m",
    "open_il_12m",
    "open_act_il",
    "max_bal_bc",
    "inq_fi",
    "total_bal_il",
    "open_rv_24m",
    "open_rv_12m"
]

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import (
    roc_auc_score, confusion_matrix, classification_report)

def print_model_output(name, model, X_test, y_test):
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_pred_proba >= 0.5).astype(int)

    auc = roc_auc_score(y_test, y_pred_proba)
    cm = confusion_matrix(y_test, y_pred)
    cr = classification_report(y_test, y_pred, digits=4)

    print(f"{name} AUC: {auc:.4f}")

    print("\nConfusion Matrix:")
    print(cm)

    print("\nClassification Report:")
    print(cr)

# Function to dummy encode categorical variables
def encode_categoricals(X):
    X = pd.get_dummies(
        X,
        columns=pred_cat_pd,
        drop_first=True
    )

    return X

# Function to split data into training/testing subsets
def split_xy(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        stratify=y,
        random_state=42
    )

    return X_train, X_test, y_train, y_test



# Function to fit XGBoost models
def fit_xgb_model(X_train, y_train, n_estimators):
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

    model = XGBClassifier(
        n_estimators=n_estimators,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        eval_metric="auc",
        scale_pos_weight=scale_pos_weight,
        tree_method="hist",
        n_jobs=-1,
        random_state=42
    )

    model.fit(X_train, y_train)

    return model

pred_num_final_pd = (
    pred_num_pd
    + joint_conditionals_pd
    + interaction_delinq_pd
    + recent_credit_vars_2016_pd
)

# subset data
X = df_post2016[pred_cat_pd + pred_num_final_pd].copy()
y = df_post2016["default"].copy()

# fill missing credit variables with 0
for col in recent_credit_vars_2016_pd:
    X[col] = X[col].fillna(0)

# encode categoricals
X = encode_categoricals(X)

# train/test split
X_train, X_test, y_train, y_test = split_xy(
    X,
    y
) 
```

```{python}
pd_xgb_post_out = fit_xgb_model(
    X_train,
    y_train,
    n_estimators=500
)

pd_hat = pd_xgb_post_out.predict_proba(X_test)[:, 1]

pd_xgb_post_out = {
    "model": pd_xgb_post_out,
    "y_pred": pd_hat
}

print("\nPOST-2016 XGBOOST")
print_model_output(
    "Post-2016 XGBoost",
    pd_xgb_post_out["model"],
    X_test,
    y_test
)
```

### LGD Model (same as before)

```{python}
df_lgd["post_2016"] = df_lgd["issue_d"].dt.year >= 2016

df_lgd["post_2016"].value_counts().rename({
    False: "pre_2016",
    True: "post_2016"
})

df_post2016 = df_lgd[df_lgd["issue_d"].dt.year >= 2016].copy()


num_pred_lgd = [
    # loan structure
    "loan_amnt", 
    "int_rate",

    # borrower info
    "emp_length",
    "annual_inc",
    "dti",
    "fico_range_low",

    # credit quality
    "delinq_2yrs",
    "pub_rec_bankruptcies",
    "tax_liens",
    "collections_12_mths_ex_med",
    "chargeoff_within_12_mths",

    # credit activity
    "open_acc",
    "total_acc",
    "mort_acc",
    "inq_last_6mths",
    "acc_open_past_24mths",
    "num_rev_accts",
    "num_il_tl",

    #Credit account info
    "revol_bal",
    "revol_util",
    "total_bc_limit",
    "bc_util"
]

cat_pred_lgd = [
    "term",
    "region",
    "home_ownership",
]

flag_pred_lgd = [
    "joint_flag",
    "hardship_flag",
    "verified_flag",
    "whole_loan_flag"
]

#Post 2016 only variables
credit_util_2016_pred_lgd = [
    "il_util",
    "mths_since_rcnt_il",
    "all_util",
    "max_bal_bc",
    "total_bal_il",
]

#Additional variables to be included for XGBoost
xgboost_pred_lgd = [
    #Credit account info
    "total_bal_ex_mort",
    "avg_cur_bal",
    "percent_bc_gt_75",
    "bc_open_to_buy",
    "total_rev_hi_lim",
    "total_bc_limit",
    "total_il_high_credit_limit",
]

#Additional variables for XGBoost - only post-2016
xgboost_credit_util_2016_pred_lgd = [
    "inq_last_12m",
    "total_cu_tl",
    "open_il_24m",
    "open_il_12m",
    "open_act_il",
    "open_rv_24m",
    "open_rv_12m",
    "inq_fi",
    "open_acc_6m",
]

import numpy as np
from sklearn.metrics import mean_absolute_error
import xgboost as xgb


df_post2016[credit_util_2016_pred_lgd] = (
    df_post2016[credit_util_2016_pred_lgd].fillna(0)
)

#Function to encode categorical predictors
def encode_categoricals(X, pred_cat):
    X = pd.get_dummies(
        X,
        columns=pred_cat,
        drop_first=True
    )
    return X

#Function to preprocess data for XGBoost
def prep_xgb_matrix(df, predictors, cat_pred):

    X = df[predictors].copy()

    # Encode categoricals
    X = pd.get_dummies(X, columns=cat_pred, drop_first=True)


    # Replace inf from ratios
    X.replace([np.inf, -np.inf], np.nan, inplace=True)

    # XGBoost handles 0 well; use 0 for structural missingness
    X = X.fillna(0)

    return X.astype(float)

#Function to fit XGBoost model
def fit_xgboost_lgd(
    X_train,
    y_train,
    X_test,
    y_test,
    params=None,
    num_boost_round=500,
    early_stopping_rounds=50,
    verbose=False,
    name="XGBoost LGD"
):
    

    # Parameters
    if params is None:
        params = {
            "objective": "reg:squarederror",
            "eval_metric": "mae",
            "learning_rate": 0.05,
            "max_depth": 4,
            "min_child_weight": 50,
            "subsample": 0.8,
            "colsample_bytree": 0.8,
            "seed": 42,
        }

    # DMatrix
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest  = xgb.DMatrix(X_test, label=y_test)

    evals = [(dtrain, "train"), (dtest, "test")]

    # Train
    model = xgb.train(
        params=params,
        dtrain=dtrain,
        num_boost_round=num_boost_round,
        evals=evals,
        early_stopping_rounds=early_stopping_rounds,
        verbose_eval=verbose
    )

    # Predict
    y_pred = model.predict(dtest).clip(0, 1)

    # Metrics
    mae = mean_absolute_error(y_test, y_pred)

    print(f"\n{name}")
    print(f"MAE: {mae:.4f}")

    return {
        "model": model,
        "mae": mae,
        "y_pred": y_pred
    }
```


```{python}
TARGET = "lgd"

# Define predictors
xgb_post_predictors_lgd = (
    num_pred_lgd
    + xgboost_pred_lgd
    + xgboost_credit_util_2016_pred_lgd
    + cat_pred_lgd
    + flag_pred_lgd
)

X_post = prep_xgb_matrix(
    df_post2016, xgb_post_predictors_lgd, cat_pred_lgd)
y_post = df_post2016[TARGET].astype(float).clip(0, 1)

# Train/test split
X_train_post, X_test_post, y_train_post, y_test_post = train_test_split(
    X_post, y_post, test_size=0.2, random_state=42
)

# Fit model
lgd_xgb_post_out = fit_xgboost_lgd(
    X_train=X_train_post.values,
    y_train=y_train_post.values,
    X_test=X_test_post.values,
    y_test=y_test_post.values,
    name="Post-2016 XGBoost LGD"
)
```





```{python}
# ============================================================
# EXPECTED LOSS (EL) SCORING PIPELINE
# ============================================================

import numpy as np
import pandas as pd
import xgboost as xgb


# ============================================================
# 1) DEFINE EL POPULATION (ALL NON-CURRENT, POST-2016 LOANS)
# ============================================================

df_el = df.loc[
    (df["current_flag"] == 0) &
    (df["issue_d"].dt.year >= 2016)
].copy()


# ============================================================
# 2) DEFINE FINAL PREDICTOR LISTS (COMBINATIONS ONLY)
# ============================================================

# ---- PD predictors (exactly what PD was trained on) ----
xgb_post_predictors_pd = (
    pred_num_pd
    + recent_credit_vars_2016_pd
    + joint_conditionals_pd
    + interaction_delinq_pd
    + pred_cat_pd
)

# ---- LGD predictors (exactly what LGD was trained on) ----
xgb_post_predictors_lgd = (
    num_pred_lgd
    + xgboost_pred_lgd
    + xgboost_credit_util_2016_pred_lgd
    + cat_pred_lgd
    + flag_pred_lgd
)


# ============================================================
# 3) SCORE PD ON ALL LOANS IN df_el
# ============================================================

X_pd_all = prep_xgb_matrix(
    df_el,
    predictors=xgb_post_predictors_pd,
    cat_pred=pred_cat_pd
)

df_el["pd_hat"] = (
    pd_xgb_post_out["model"]
    .predict_proba(X_pd_all.values)[:, 1]
)


# ============================================================
# 4) SCORE LGD ONLY ON DEFAULTED LOANS
# ============================================================

default_mask = df_el["default"] == 1

X_lgd = prep_xgb_matrix(
    df_el.loc[default_mask],
    predictors=xgb_post_predictors_lgd,
    cat_pred=cat_pred_lgd
)

df_el.loc[default_mask, "lgd_hat"] = (
    lgd_xgb_post_out["model"]
    .predict(xgb.DMatrix(X_lgd.values))
    .clip(0, 1)
)


# ============================================================
# 5) SET LGD = 0 FOR NON-DEFAULTED LOANS
# ============================================================

df_el["lgd_hat"] = df_el["lgd_hat"].fillna(0)


# ============================================================
# 6) DEFINE EAD AND COMPUTE EXPECTED LOSS
# ============================================================

df_el["ead"] = df_el["loan_amnt"]

df_el["el_hat"] = (
    df_el["pd_hat"]
    * df_el["lgd_hat"]
    * df_el["ead"]
)


# ============================================================
# 7) SANITY CHECKS
# ============================================================

print("\nPD / LGD / EL Summary:")
print(df_el[["pd_hat", "lgd_hat", "el_hat"]].describe())


# ============================================================
# 8) EL DECILE CALIBRATION
# ============================================================

df_el["el_decile"] = pd.qcut(
    df_el["el_hat"],
    q=10,
    labels=False,
    duplicates="drop"
)


el_calibration = (
    df_el
    .groupby("el_decile")
    .agg(
        mean_pd=("pd_hat", "mean"),
        mean_lgd=("lgd_hat", "mean"),
        mean_ead=("ead", "mean"),
        mean_el=("el_hat", "mean"),
        count=("el_hat", "size")
    )
)

print("\nEL Calibration by Decile:")
print(el_calibration)


# ============================================================
# 9) LOSS CONCENTRATION (OPTIONAL BUT STRONG RESULT)
# ============================================================

total_el = df_el["el_hat"].sum()

top10_share = (
    df_el
    .sort_values("el_hat", ascending=False)
    .head(int(0.10 * len(df_el)))["el_hat"]
    .sum()
    / total_el
)

print(f"\nTop 10% of loans account for {top10_share:.1%} of predicted EL")

```

```{python}
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt


# ----------------------------
# 1) CONFIG (same as your lists)
# ----------------------------
pred_cat_pd = ["term", "region", "home_ownership"]

pred_num_pd = [
    # loan structure
    "loan_amnt", 

    # borrower capacity
    "annual_inc", "emp_length", "dti",

    # credit quality
    "fico_range_low", "fico_range_high", "delinq_2yrs", "pub_rec",
    "pub_rec_bankruptcies", "collections_12_mths_ex_med",
    "chargeoff_within_12_mths", "tax_liens",

    # credit account info
    "revol_bal", "revol_util", "total_bal_ex_mort", "avg_cur_bal",
    "bc_util", "percent_bc_gt_75", "bc_open_to_buy", "total_rev_hi_lim",
    "total_bc_limit", "total_il_high_credit_limit",

    # credit depth & activity
    "open_acc", "total_acc", "mort_acc", "inq_last_6mths",
    "acc_open_past_24mths", "num_rev_accts", "num_il_tl", "num_op_rev_tl",
    "num_sats",

    # flags
    "joint_flag", "verified_flag", "verified_flag_joint", "whole_loan_flag",

    # structural missingness flags
    "mths_since_last_record_flag",
    "mths_since_recent_bc_dlq_flag",
    "mths_since_last_major_derog_flag",
    "mths_since_recent_revol_delinq_flag",
    "mths_since_last_delinq_flag",
]

joint_numeric_pred_pd = [
    "sec_app_mths_since_last_major_derog",
    "sec_app_revol_util",
    "revol_bal_joint",
    "sec_app_open_acc",
    "sec_app_num_rev_accts",
    "sec_app_inq_last_6mths",
    "sec_app_mort_acc",
    "sec_app_open_act_il",
    "sec_app_fico_range_low",
    "sec_app_fico_range_high",
    "sec_app_chargeoff_within_12_mths",
    "sec_app_collections_12_mths_ex_med",
    "dti_joint",
    "annual_inc_joint"
]

flag_to_var = {
    "mths_since_last_record_flag": "mths_since_last_record",
    "mths_since_recent_bc_dlq_flag": "mths_since_recent_bc_dlq",
    "mths_since_last_major_derog_flag": "mths_since_last_major_derog",
    "mths_since_recent_revol_delinq_flag": "mths_since_recent_revol_delinq",
    "mths_since_last_delinq_flag": "mths_since_last_delinq",
}

recent_credit_vars_2016_pd = [
    "il_util",
    "mths_since_rcnt_il",
    "all_util",
    "open_acc_6m",
    "inq_last_12m",
    "total_cu_tl",
    "open_il_24m",
    "open_il_12m",
    "open_act_il",
    "max_bal_bc",
    "inq_fi",
    "total_bal_il",
    "open_rv_24m",
    "open_rv_12m"
]


# ----------------------------
# 2) HELPERS
# ----------------------------
def print_model_output(name, model, X_test, y_test):
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_pred_proba >= 0.5).astype(int)

    auc = roc_auc_score(y_test, y_pred_proba)
    cm = confusion_matrix(y_test, y_pred)
    cr = classification_report(y_test, y_pred, digits=4)

    print(f"{name} AUC: {auc:.4f}")
    print("\nConfusion Matrix:")
    print(cm)
    print("\nClassification Report:")
    print(cr)


def split_xy(X, y):
    return train_test_split(
        X, y,
        test_size=0.2,
        stratify=y,
        random_state=42
    )


def fit_xgb_model(X_train, y_train, n_estimators=500):
    # handle imbalance
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

    model = XGBClassifier(
        n_estimators=n_estimators,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        eval_metric="auc",
        scale_pos_weight=scale_pos_weight,
        tree_method="hist",
        n_jobs=-1,
        random_state=42
    )
    model.fit(X_train, y_train)
    return model


def build_pd_features(df_in: pd.DataFrame, train_columns=None):
    """
    Applies the SAME PD feature engineering used for training:
      - joint conditional interactions
      - delinquency 'since' interactions with flags
      - fills recent credit vars with 0
      - one-hot encodes categoricals
      - optionally aligns columns to training columns
    """
    df = df_in.copy()

    # --- joint conditional features
    joint_conditionals_pd = []
    for var in joint_numeric_pred_pd:
        if var not in df.columns:
            df[var] = 0
        df[var] = df[var].fillna(0)
        df[f"{var}_active"] = df["joint_flag"] * df[var]
        joint_conditionals_pd.append(f"{var}_active")

    # --- delinquency interaction features
    interaction_delinq_pd = []
    for flag, var in flag_to_var.items():
        if var not in df.columns:
            df[var] = 0
        df[var] = df[var].replace(999, 0).fillna(0)
        df[f"{var}_active"] = df[flag] * df[var]
        interaction_delinq_pd.append(f"{var}_active")

    pred_num_final_pd = pred_num_pd + joint_conditionals_pd + interaction_delinq_pd + recent_credit_vars_2016_pd

    # ensure all expected columns exist
    needed = pred_cat_pd + pred_num_final_pd
    for c in needed:
        if c not in df.columns:
            df[c] = 0

    X = df[needed].copy()

    # fill missing recent credit vars
    for col in recent_credit_vars_2016_pd:
        X[col] = X[col].fillna(0)

    # encode categoricals (drop_first=True exactly like training)
    X = pd.get_dummies(X, columns=pred_cat_pd, drop_first=True)

    # align to training columns if provided (CRITICAL for scoring!)
    if train_columns is not None:
        X = X.reindex(columns=train_columns, fill_value=0)

    return X


# ----------------------------
# 3) TRAIN PD MODEL (non-current, post-2016)
# ----------------------------
df_full["issue_d"] = pd.to_datetime(df_full["issue_d"])

df_train = df_full.loc[
    (df_full["current_flag"] == 0) &
    (df_full["issue_d"].dt.year >= 2016)
].copy()

y_train = df_train["default"]

X_train = build_pd_features(df_train)
train_cols = X_train.columns.tolist()

X_tr, X_te, y_tr, y_te = train_test_split(
    X_train,
    y_train,
    test_size=0.2,
    stratify=y_train,
    random_state=42
)

pd_model = fit_xgb_model(X_tr, y_tr)

auc = roc_auc_score(y_te, pd_model.predict_proba(X_te)[:, 1])
print(f"Post-2016 PD Model AUC: {auc:.4f}")


# ------------------------------------------------------------
# 5) SCORE ACTIVE (CURRENT) POST-2016 LOANS
# ------------------------------------------------------------
df_current = df_full.loc[
    (df_full["current_flag"] == 1) &
    (df_full["issue_d"].dt.year >= 2016)
].copy()

X_current = build_pd_features(df_current, train_columns=train_cols)

df_current["pd_hat"] = pd_model.predict_proba(X_current)[:, 1]


# ------------------------------------------------------------
# 6) EXPECTED DEFAULTS & DEFAULT RATE
# ------------------------------------------------------------
n_loans = len(df_current)
expected_defaults = df_current["pd_hat"].sum()
expected_default_rate = expected_defaults / n_loans

print("\nPOST-2016 ACTIVE LOANS")
print(f"Number of loans: {n_loans:,}")
print(f"Expected number of defaults: {expected_defaults:,.1f}")
print(f"Expected default rate: {expected_default_rate:.2%}")

```

```{python}
print("Train default rate:", df_train["default"].mean())
print("Avg PD on current loans:", df_current["pd_hat"].mean())

```